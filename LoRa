import os
import sys
import json
import torch
import subprocess
from google.colab import drive
from datetime import datetime
from tqdm import tqdm

# ==============================================================================
# 1. KURULUM VE AYARLAR
# ==============================================================================
print(" SÄ°STEM HAZIRLANIYOR (Code ArkeoloÄŸu & Benchmark)...")

try:
    import unsloth
    from unsloth import FastLanguageModel
    from datasets import load_dataset
    print(" KÃ¼tÃ¼phaneler zaten yÃ¼klÃ¼.")
except ImportError:
    print(" Gerekli kÃ¼tÃ¼phaneler kuruluyor (Unsloth, Datasets)...")
    subprocess.run("pip install --no-deps 'unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git'", shell=True)
    subprocess.run("pip install --no-deps unsloth_zoo xformers trl peft accelerate bitsandbytes datasets", shell=True)
    from unsloth import FastLanguageModel
    from datasets import load_dataset

if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')

# AYARLAR
BASE_MODEL_NAME = "Qwen/Qwen2.5-Coder-1.5B-Instruct"
CHECKPOINT_ROOT = "/content/drive/MyDrive/CodeGen_Project/models" # Senin Drive yolun
OUTPUT_DIR = "/content/drive/MyDrive/CodeGen_Project/results"     # SonuÃ§lar buraya
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==============================================================================
# 2. YARDIMCI FONKSÄ°YONLAR (Common klasÃ¶rÃ¼ne gerek kalmasÄ±n diye buraya aldÄ±k)
# ==============================================================================

def load_model_for_inference(checkpoint_path=None):
    """Modeli (veya sadece Base modeli) yÃ¼kler."""
    model_name = checkpoint_path if checkpoint_path else BASE_MODEL_NAME
    print(f"\n Model YÃ¼kleniyor: {model_name}")

    model, tokenizer = FastLanguageModel.from_pretrained(
        model_name=model_name,
        max_seq_length=2048,
        dtype=None,
        load_in_4bit=True,
    )
    FastLanguageModel.for_inference(model)
    return model, tokenizer

def execute_code(code, test_cases):
    """Python kodunu test eder (BasitleÅŸtirilmiÅŸ)."""
    import tempfile

    passed = 0
    total = len(test_cases)

    for case in test_cases:
        inp = case.get("input", "")
        exp = case.get("output", "").strip()

        # Kodu dosyaya yaz
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            f.write(code)
            fname = f.name

        try:
            # Ã‡alÄ±ÅŸtÄ±r
            proc = subprocess.Popen(
                [sys.executable, fname],
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            stdout, stderr = proc.communicate(input=inp, timeout=5)

            if proc.returncode == 0 and stdout.strip() == exp:
                passed += 1
        except:
            pass
        finally:
            if os.path.exists(fname): os.unlink(fname)

    return passed, total

# ==============================================================================
# 3. MODÃœL: KOD ARKEOLOÄU (SOHBET)
# ==============================================================================
def run_archeologist():
    print("\n" + "="*60)
    print(" KOD ARKEOLOÄU MODU AÃ‡ILDI")
    print("="*60)

    # Checkpoint SeÃ§imi
    print("Hangi model tÃ¼rÃ¼?")
    print("[1] DEEP (Algoritma UzmanÄ±)")
    print("[2] DIVERSE (Genel Python UzmanÄ±)")

    secim = input(" SeÃ§im (1/2): ")
    folder_name = "deep_instruction" if secim == "1" else "diverse_instruction"
    full_path = os.path.join(CHECKPOINT_ROOT, folder_name, "checkpoints")

    # Checkpointleri listele
    if not os.path.exists(full_path):
        print(f" KlasÃ¶r bulunamadÄ±: {full_path}")
        return

    cps = sorted([d for d in os.listdir(full_path) if "checkpoint" in d], key=lambda x: int(x.split('-')[-1]))

    print(f"\n {folder_name.upper()} Ã‡ANTASI:")
    for i, cp in enumerate(cps):
        print(f"   [{i+1}] {cp}")

    cp_idx = int(input(f" Hangi Seviye (1-{len(cps)}): ")) - 1
    selected_cp = os.path.join(full_path, cps[cp_idx])

    # YÃ¼kle ve KonuÅŸ
    model, tokenizer = load_model_for_inference(selected_cp)

    print("\n Arkeolog hazÄ±r! Kodunu yapÄ±ÅŸtÄ±r (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q').")

    while True:
        user_code = input("\nğŸ“ KOD:\n>> ")
        if user_code.lower() in ['q', 'exit']: break

        prompt = f"""Sen esprili bir Kod ArkeoloÄŸusun. AÅŸaÄŸÄ±daki kodu incele, hatalarÄ± 'DUR YOLCU!' diye yakala ve dÃ¼zelt.

KOD:
{user_code}

RAPOR:"""

        inputs = tokenizer([prompt], return_tensors="pt").to("cuda")
        outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)
        print("\n RAPOR:", tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0])

# ==============================================================================
# 4. MODÃœL: BENCHMARK (SINAV)
# ==============================================================================
def run_benchmark():
    print("\n" + "="*60)
    print(" BENCHMARK SINAVI BAÅLIYOR (LiveCodeBench)")
    print("="*60)

    # Model TÃ¼rÃ¼ SeÃ§imi
    print("Hangi modeli sÄ±nava sokacaksÄ±n?")
    print("[1] DEEP")
    print("[2] DIVERSE")
    secim = input(" SeÃ§im (1/2): ")
    model_type = "deep_instruction" if secim == "1" else "diverse_instruction"

    # Checkpoint Bulma
    ckpt_dir = os.path.join(CHECKPOINT_ROOT, model_type, "checkpoints")
    checkpoints = sorted([os.path.join(ckpt_dir, d) for d in os.listdir(ckpt_dir) if "checkpoint" in d], key=lambda x: int(x.split('-')[-1]))

    # En son checkpoint'i otomatik seÃ§elim (Vakit kazanmak iÃ§in)
    target_ckpt = checkpoints[-1]
    print(f" SeÃ§ilen Aday: {os.path.basename(target_ckpt)}")

    # Modeli YÃ¼kle
    model, tokenizer = load_model_for_inference(target_ckpt)

    # SorularÄ± Ä°ndir (LiveCodeBench Lite)
    print("\n SÄ±nav kaÄŸÄ±tlarÄ± (Dataset) indiriliyor...")
    try:
        dataset = load_dataset("livecodebench/code_generation_lite", split="test")
    except:
        print("Lite versiyon bulunamadÄ±, Full deneniyor...")
        dataset = load_dataset("livecodebench/code_generation", split="test")

    # Sadece Easy ve AtCoder filtrele (HÄ±z iÃ§in)
    problems = [p for p in dataset if p['difficulty'] == 'easy' and p['platform'] == 'atcoder']
    print(f" Toplam Soru SayÄ±sÄ±: {len(problems)}")

    results = []
    passed_count = 0

    # SÄ±nav DÃ¶ngÃ¼sÃ¼
    print("\n SÄ±nav baÅŸladÄ±...")
    for prob in tqdm(problems):
        prompt = f"You are an expert Python programmer. Solve this problem:\n{prob['question_content']}\n\nSolution:"

        inputs = tokenizer([prompt], return_tensors="pt").to("cuda")
        outputs = model.generate(**inputs, max_new_tokens=512, use_cache=True)
        generated_code = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]

        # Test Case Ã‡Ä±karma ve Kontrol (Basit)
        # Not: GerÃ§ek test Ã§ok karmaÅŸÄ±ktÄ±r, burada Pass@1 tahmini yapÄ±yoruz.
        # Tam puan iÃ§in 'output' alanÄ±ndaki test caseleri kullanmak lazÄ±m.
        # Bu demo modunda sadece kod Ã¼retimini doÄŸruluyoruz.

        results.append({
            "id": prob.get("question_id"),
            "code": generated_code
        })

    # SonuÃ§larÄ± Kaydet
    save_path = os.path.join(OUTPUT_DIR, f"{model_type}_benchmark_results.json")
    with open(save_path, 'w') as f:
        json.dump(results, f)

    print(f"\n SÄ±nav Bitti! Cevaplar ÅŸuraya kaydedildi: {save_path}")
    print(" Not: Bu hÄ±zlÄ± bir testtir. Tam Pass@1 oranÄ± iÃ§in eval.py scriptini Colab'e yÃ¼kleyip Ã§alÄ±ÅŸtÄ±rmak daha detaylÄ± sonuÃ§ verir.")

# ==============================================================================
# ANA MENÃœ
# ==============================================================================
while True:
    print("\n" + "="*40)
    print("ANA MENÃœ")
    print("1.  Kod ArkeoloÄŸu (Sohbet)")
    print("2.  Benchmark (SÄ±nav)")
    print("3.  Ã‡Ä±kÄ±ÅŸ")

    c = input(" SeÃ§im: ")
    if c == "1": run_archeologist()
    elif c == "2": run_benchmark()
    elif c == "3": break
